{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(os.path.join(os.getcwd(),\"Ambiente.env\"))\n",
    "azure_openai_endpoint = os.getenv(\"openai_endpoint\")\n",
    "azure_openai_key = os.getenv(\"openai_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ristoranti = [\"Michelangelo\", \"Raffaello\", \"ying-yang\", \"Haveli\", \"Bella Italia\", \"Pizza360\", \"Wen\", \"Ritual\", \"Pegaso\", \"Greek Taverna\", \"My kimchi\", \"Istanbul\", \"Fusion\", \"Nippo\", \"Sushi Club\", \"Tao\", \"Gustoo\", \"Da Mario\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dizionario_cucine = {\"cinese\": [\"ying-yang\", \"Wen\"], \"giapponese\": [\"Nippo\", \"Fusion\", \"Sushi Club\", \"Tao\"], \"italiana\": [\"Bella Italia\", \"Pizza360\", \"Gustoo\", \"Da Mario\", \"Michelangelo\", \"Raffaello\"], \"turca\": [\"Istanbul\"], \"malesiano\": [\"Pegaso\"], \"indiano\": [\"Haveli\"], \"greco\": [\"Greek Taverna\"], \"messicano\": [\"Ritual\"], \"coreano\": [\"My kimchi\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_partenza = AzureChatOpenAI(\n",
    "deployment_name =\"init-test-gpt-35-turbo\",\n",
    "model=\"gpt-35-turbo\",\n",
    "azure_endpoint = azure_openai_endpoint,\n",
    "openai_api_type=\"azure\",\n",
    "openai_api_version = '2023-05-15',\n",
    "openai_api_key = azure_openai_key,\n",
    "temperature=0)\n",
    "\n",
    "answer_prompt_nota = PromptTemplate.from_template(\n",
    "    \"\"\"Data una lista di luoghi: {ristoranti} e una parola in entrata: {question}, trova nella lista la parola più simile o quella uguale, se c'è. La risposta deve contenere solo la parola selezionata dalla lista, scritta esattamente com'era scritta nella lista.\n",
    "        Esempio: Lista di luoghi: [\"Roma\", \"Milano\", \"Firenze\", \"Napoli\"] Parola in entrata: \"Milano\"\n",
    "        Risposta: Milano\n",
    "        Lista di luoghi: [\"Roma\", \"Milano\", \"Firenze\", \"Napoli\"] Parola in entrata: \"Napl\"\n",
    "        Risposta: Napoli\n",
    "       \n",
    "        Rispondi solo con la risposta\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "answer_nota = answer_prompt_nota | llm_partenza  \n",
    "chain_nota = answer_nota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cinese'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risposta = chain_nota.invoke({\"question\": \"cinese\", \"ristoranti\": dizionario_cucine.keys()}).content\n",
    "risposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wen'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risposta = chain_nota.invoke({\"question\": \"wen\", \"ristoranti\": ristoranti}).content\n",
    "risposta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
